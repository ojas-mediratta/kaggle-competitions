{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "17da29da",
      "metadata": {
        "id": "17da29da"
      },
      "source": [
        "### All Shapes and Colors - Kaggle Challenge ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2b5a4e80",
      "metadata": {
        "id": "2b5a4e80",
        "outputId": "ef7517a7-e75e-44c7-926b-70a40a50f3c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Imports\n",
        "import os, ast, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def seed_everything(seed=17):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "seed_everything(17)\n",
        "\n",
        "# Device (prototyped on my MacBook Air M1)\n",
        "device = torch.device(\n",
        "    \"mps\" if torch.backends.mps.is_available() else\n",
        "    (\"cuda\" if torch.cuda.is_available() else \"cpu\") # for colab compatibility\n",
        ")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ef0d1be",
      "metadata": {
        "id": "9ef0d1be"
      },
      "source": [
        "After looking at the problem, I can see we have the following constraints:\n",
        "- Each image contains k objects where 1 <= k <= 9, since there are no duplicate objects with same (shape, color) in any given image.\n",
        "- we can have multiple of the same shape and multiple of the same color in the image.\n",
        "\n",
        "I'll want to use a multi-label target over all 9 possible pairs. For each image, the target is a 9-dimension one-hot vector with a one for each present pair in the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4fa09862",
      "metadata": {
        "id": "4fa09862",
        "outputId": "dfdc174c-ccbc-4112-bedb-1bfa3203c51b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'circle_red': 0, 'circle_green': 1, 'circle_blue': 2, 'square_red': 3, 'square_green': 4, 'square_blue': 5, 'triangle_red': 6, 'triangle_green': 7, 'triangle_blue': 8}\n",
            "{0: 'circle_red', 1: 'circle_green', 2: 'circle_blue', 3: 'square_red', 4: 'square_green', 5: 'square_blue', 6: 'triangle_red', 7: 'triangle_green', 8: 'triangle_blue'}\n"
          ]
        }
      ],
      "source": [
        "SHAPES = ['circle', 'square', 'triangle']\n",
        "COLORS = ['red', 'green', 'blue']\n",
        "\n",
        "# assign each (shape, color) pair an index\n",
        "PAIR_TO_IDX = {\n",
        "    f\"{shape}_{color}\": i\n",
        "    for i, (shape, color) in enumerate(\n",
        "        (s, c) for s in SHAPES for c in COLORS\n",
        "    )\n",
        "}\n",
        "\n",
        "IDX_TO_PAIR = {v: k for k, v in PAIR_TO_IDX.items()} # need this to decode predictions\n",
        "\n",
        "print(PAIR_TO_IDX)\n",
        "print(IDX_TO_PAIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c71bf47",
      "metadata": {
        "id": "0c71bf47"
      },
      "source": [
        "Step one is to setup label representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "28b547df",
      "metadata": {
        "id": "28b547df"
      },
      "outputs": [],
      "source": [
        "# Encoding the pairs to multi-hot vector\n",
        "def encode_pairs(pairs):\n",
        "    \"\"\"\n",
        "    Encode a list of (shape, color) pairs to a multi-hot vector.\n",
        "    pairs: list of tuples (shape, color)\n",
        "    returns: torch tensor of shape (9,)\n",
        "    \"\"\"\n",
        "    target = np.zeros(len(PAIR_TO_IDX), dtype=np.float32)\n",
        "    for shape, color in pairs:\n",
        "        shape, color = shape.lower(), color.lower()\n",
        "        key = f\"{shape}_{color}\"\n",
        "        y = PAIR_TO_IDX[key]\n",
        "        target[y] = 1.0\n",
        "    target = torch.from_numpy(target)\n",
        "    return target\n",
        "\n",
        "# pairs = [(\"circle\",\"red\"), (\"triangle\",\"blue\")]\n",
        "# y = encode_pairs(pairs)\n",
        "# print(y)\n",
        "# print(y.sum())\n",
        "\n",
        "def decode_vec(y):\n",
        "    \"\"\"\n",
        "    Decode a multi-hot vector to a list of (shape, color) pairs.\n",
        "    y: torch tensor of shape (9,)\n",
        "    returns: list of tuples (shape, color)\n",
        "    \"\"\"\n",
        "    probs = torch.sigmoid(y) # convert logits to probabilities using sigmoid (will give values between 0 and 1)\n",
        "    idxs = (probs >= 0.5).nonzero(as_tuple=True)[0].tolist() # threshold at 0.5\n",
        "    pairs = []\n",
        "    for i in idxs:\n",
        "        pair = IDX_TO_PAIR[i]\n",
        "        shape, color = pair.split(\"_\")\n",
        "        pairs.append((shape, color))\n",
        "    return pairs\n",
        "\n",
        "\n",
        "# logits = torch.tensor([3.0, -1.0, 0.2, 0.0, 0.0, 2.5, -2.0, 0.0, 0.0])\n",
        "# decoded = decode_vec(logits)\n",
        "# print(decoded)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a74f72",
      "metadata": {
        "id": "43a74f72"
      },
      "source": [
        "There's a function to make the data usable for training. I represent the labels as the 9-dim tensor mentioned earlier.\n",
        "\n",
        "I also have a function to decode the tensor outputted at inference time. It applies a sigmoid to get probabilities, thresholds, then turns the tensor back into (shape, color) tuples.\n",
        "\n",
        "Next thing to do is load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e1a75383",
      "metadata": {
        "id": "e1a75383"
      },
      "outputs": [],
      "source": [
        "def parse_label_string(string): # need this since the CSV has labels as strings\n",
        "    \"\"\"\n",
        "    Parse a label string into a list of (shape, color) pairs.\n",
        "    string: str, e.g. \"[(circle_red), (triangle_blue)]\" or \"[]\"\n",
        "    returns: list of tuples (shape, color)\n",
        "    \"\"\"\n",
        "    if string == \"\" or string == \"[]\" or string is None: #handle null or empty arg\n",
        "        return []\n",
        "    s = string.lower().strip()\n",
        "    data = ast.literal_eval(s) # turn the string into a list of tuples\n",
        "    # normalize the tuples\n",
        "    data = [(shape.strip().lower(), color.strip().lower()) for shape, color in data]\n",
        "    return data\n",
        "\n",
        "# test parser\n",
        "# samples = [\n",
        "#     \"[('square', 'blue'), ('circle', 'green'), ('square', 'red')]\",\n",
        "#     \"[('circle','blue'),('square','green'),('circle','red'),('square','red')]\",\n",
        "#     \"[]\"\n",
        "# ]\n",
        "# for s in samples:\n",
        "#     pairs = parse_label_string(s)\n",
        "#     assert isinstance(pairs, list), \"Parser should return a list\"\n",
        "#     for (shape, color) in pairs:\n",
        "#         assert shape in SHAPES and color in COLORS, f\"Bad pair parsed: {(shape,color)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2b526fd",
      "metadata": {
        "id": "b2b526fd"
      },
      "source": [
        "Creating dataset classes here. I use pillow to load the images and apply transformations. In this case I'm just doing normalization since the provided images already look like they have distortion and noise applied. No resizing either. I may add image augmentation if validation suggests any overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cbe3ce33",
      "metadata": {
        "id": "cbe3ce33"
      },
      "outputs": [],
      "source": [
        "# Datasets\n",
        "class ShapesColorsDatasetTrain(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for training and validation: (image_tensor, target_vector)\n",
        "    CSV columns: image_path, label\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # resolve image path\n",
        "        rel = str(row[\"image_path\"])\n",
        "        img_path = rel if os.path.isabs(rel) else os.path.join(self.img_dir, rel)\n",
        "\n",
        "        # load image with pillow and force rgb color space\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # apply any preprocessing transforms\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # parse and encode label\n",
        "        pairs = parse_label_string(row[\"label\"])\n",
        "        target = encode_pairs(pairs)\n",
        "\n",
        "        # return tensors ready for the model and loss\n",
        "        return img, target\n",
        "\n",
        "class ShapesColorsDatasetTest(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for testing: (image_tensor, image_path)\n",
        "    CSV column: image_path\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        rel = str(self.df.iloc[idx][\"image_path\"])\n",
        "        img_path = rel if os.path.isabs(rel) else os.path.join(self.img_dir, rel)\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, rel\n",
        "\n",
        "# Create datasets using existing classes with index subsets\n",
        "class IndexedDataset(Dataset):\n",
        "    def __init__(self, base_dataset, indices):\n",
        "        self.base_dataset = base_dataset\n",
        "        self.indices = indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.base_dataset[self.indices[idx]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7ac2daa",
      "metadata": {
        "id": "c7ac2daa"
      },
      "source": [
        "Transforms and loaders. I'm using a batch size of 32, shuffling for training, and numworkers = 2. I set numworkers to 0 while working on my Mac, but I'll bring those back if I move to a Colab env. Seems like this dataset is small enough that my M1 should be okay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dbb6079a",
      "metadata": {
        "id": "dbb6079a",
        "outputId": "e407aa1a-c797-4079-9eb0-973c57b0579f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'all-shapes-and-colors-v-2/dataset_v3/train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-291178697.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load and split training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'all-shapes-and-colors-v-2/dataset_v3/train.csv'"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "# File paths\n",
        "train_csv = \"all-shapes-and-colors-v-2/dataset_v3/train.csv\"\n",
        "test_csv = \"all-shapes-and-colors-v-2/dataset_v3/test.csv\"\n",
        "train_img_dir = \"all-shapes-and-colors-v-2/dataset_v3\"\n",
        "test_img_dir = \"all-shapes-and-colors-v-2/dataset_v3\"\n",
        "\n",
        "# Load and split training data\n",
        "train_df = pd.read_csv(train_csv)\n",
        "np.random.seed(17)\n",
        "indices = np.random.permutation(len(train_df))\n",
        "split_idx = int(0.8 * len(indices)) # 80 20 split ratio for the training and validation sets\n",
        "train_indices, val_indices = indices[:split_idx], indices[split_idx:]\n",
        "\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Train split: {len(train_indices)}, Val split: {len(val_indices)}\")\n",
        "\n",
        "# Transforms\n",
        "train_tfms = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "val_tfms = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Create base training dataset and split it\n",
        "full_train_ds = ShapesColorsDatasetTrain(train_csv, train_img_dir, transform=train_tfms)\n",
        "train_ds = IndexedDataset(full_train_ds, train_indices)\n",
        "\n",
        "full_val_ds = ShapesColorsDatasetTrain(train_csv, train_img_dir, transform=val_tfms)\n",
        "val_ds = IndexedDataset(full_val_ds, val_indices)\n",
        "\n",
        "test_ds = ShapesColorsDatasetTest(test_csv, test_img_dir, transform=val_tfms)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Datasets created - Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")\n",
        "\n",
        "#test the dataset\n",
        "# x0, y0 = train_ds[0]\n",
        "# print(\"image:\", x0.shape)\n",
        "# print(\"target:\", y0)\n",
        "# print(\"num objects:\", int(y0.sum().item()))\n",
        "\n",
        "# sanity check dataloader\n",
        "def unnorm(x):\n",
        "    # invert normalize back to [0,1] for display\n",
        "    return (x * 0.5 + 0.5).clamp(0, 1)\n",
        "\n",
        "images, targets = next(iter(train_loader))\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(min(9, images.size(0))):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    img = unnorm(images[i]).permute(1, 2, 0).numpy()\n",
        "    plt.imshow(img)\n",
        "    idxs = (targets[i] > 0.5).nonzero(as_tuple=True)[0].tolist()\n",
        "    labels = [IDX_TO_PAIR[j] for j in idxs]\n",
        "    plt.title(\", \".join(labels), fontsize=9)\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "803e86ee",
      "metadata": {
        "id": "803e86ee"
      },
      "source": [
        "Onto the model. I used a small, modern CNN architecture with global average pooling. So my blocks have convolutions, batch normalization, ReLU, and then pooling. I have four of these blocks and then a global average pool before the final linear layer with the 9 logits.\n",
        "\n",
        "For loss, I've got a multi-label BCEWithLogitsLoss, which compares the 9 logits against the 9-dimensional one-hot target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64b839d9",
      "metadata": {
        "id": "64b839d9"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MyCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Small, stable CNN for multi-label (9 outputs).\n",
        "    256x256 - 128 - 64 - 32 - 16 after 4 max-pools.\n",
        "    GAP removes size dependence and keeps params small.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_out=9):\n",
        "        super().__init__()\n",
        "        def block(c_in, c_out):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(c_out),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(2)\n",
        "            )\n",
        "        self.features = nn.Sequential(\n",
        "            block(3,   32),  # 256 to 128\n",
        "            block(32,  64),  # 128 to  64\n",
        "            block(64, 128),  #  64 to  32\n",
        "            block(128,256),  #  32 to  16\n",
        "        )\n",
        "        self.gap  = nn.AdaptiveAvgPool2d(1) # [B,256,16,16] to [B,256,1,1]\n",
        "        self.head = nn.Linear(256, num_out) # 9 logits (no sigmoid)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.gap(x).flatten(1)\n",
        "        return self.head(x)\n",
        "\n",
        "model = MyCNN(num_out=9).to(device)\n",
        "sum(p.numel() for p in model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()  # multi-label\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=1e-3, # conventional learning rate for Adam\n",
        "    weight_decay=1e-4   # L2 regularization\n",
        ")\n",
        "\n",
        "# training epoch function\n",
        "def train_one_epoch(loader):\n",
        "    model.train()\n",
        "    running_loss, n = 0.0, 0\n",
        "    for images, targets in loader:\n",
        "        images, targets = images.to(device), targets.to(device)\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        n += images.size(0)\n",
        "    return running_loss / n  # average loss\n",
        "\n",
        "#validation epoch function\n",
        "def validate_one_epoch(loader):\n",
        "    model.eval()\n",
        "    running_loss, n = 0.0, 0\n",
        "    for images, targets in loader:\n",
        "        images, targets = images.to(device), targets.to(device)\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, targets)\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        n += images.size(0)\n",
        "    return running_loss / n\n",
        "\n",
        "EPOCHS = 12\n",
        "best_val = float(\"inf\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_loss = train_one_epoch(train_loader)\n",
        "    val_loss   = validate_one_epoch(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | train_loss {train_loss:.4f} | val_loss {val_loss:.4f}\")\n",
        "\n",
        "    # save best by val loss\n",
        "    if val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        torch.save(model.state_dict(), \"best_tinyscnn.pt\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "kodiak_kaggle_vision",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}