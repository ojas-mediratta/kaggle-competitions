{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17da29da",
   "metadata": {},
   "source": [
    "### All Shapes and Colors - Kaggle Challenge ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b5a4e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import os, ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device (prototyped on my MacBook Air M1)\n",
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    (\"cuda\" if torch.cuda.is_available() else \"cpu\") # for colab compatibility\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0d1be",
   "metadata": {},
   "source": [
    "After looking at the problem, I can see we have the following constraints:\n",
    "- Each image contains k objects where 1 <= k <= 9, since there are no duplicate objects with same (shape, color) in any given image.\n",
    "- we can have multiple of the same shape and multiple of the same color in the image. \n",
    "\n",
    "I'll want to use a multi-label target over all 9 possible pairs. For each image, the target is a 9-dimension one-hot vector with a one for each present pair in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa09862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'circle_red': 0, 'circle_green': 1, 'circle_blue': 2, 'square_red': 3, 'square_green': 4, 'square_blue': 5, 'triangle_red': 6, 'triangle_green': 7, 'triangle_blue': 8}\n",
      "{0: 'circle_red', 1: 'circle_green', 2: 'circle_blue', 3: 'square_red', 4: 'square_green', 5: 'square_blue', 6: 'triangle_red', 7: 'triangle_green', 8: 'triangle_blue'}\n"
     ]
    }
   ],
   "source": [
    "SHAPES = ['circle', 'square', 'triangle']\n",
    "COLORS = ['red', 'green', 'blue']\n",
    "\n",
    "# assign each (shape, color) pair an index\n",
    "PAIR_TO_IDX = {\n",
    "    f\"{shape}_{color}\": i\n",
    "    for i, (shape, color) in enumerate(\n",
    "        (s, c) for s in SHAPES for c in COLORS\n",
    "    )\n",
    "}\n",
    "\n",
    "IDX_TO_PAIR = {v: k for k, v in PAIR_TO_IDX.items()} # need this to decode predictions\n",
    "\n",
    "print(PAIR_TO_IDX)\n",
    "print(IDX_TO_PAIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c71bf47",
   "metadata": {},
   "source": [
    "Step one is to setup label representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b547df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the pairs to multi-hot vector\n",
    "def encode_pairs(pairs):\n",
    "    \"\"\"\n",
    "    Encode a list of (shape, color) pairs to a multi-hot vector.\n",
    "    pairs: list of tuples (shape, color)\n",
    "    returns: torch tensor of shape (9,)\n",
    "    \"\"\"\n",
    "    target = np.zeros(len(PAIR_TO_IDX), dtype=np.float32)\n",
    "    for shape, color in pairs:\n",
    "        shape, color = shape.lower(), color.lower()\n",
    "        key = f\"{shape}_{color}\"\n",
    "        y = PAIR_TO_IDX[key]\n",
    "        target[y] = 1.0\n",
    "    target = torch.from_numpy(target)\n",
    "    return target\n",
    "\n",
    "# pairs = [(\"circle\",\"red\"), (\"triangle\",\"blue\")]\n",
    "# y = encode_pairs(pairs)\n",
    "# print(y)        \n",
    "# print(y.sum())  \n",
    "\n",
    "def decode_vec(y):\n",
    "    \"\"\"\n",
    "    Decode a multi-hot vector to a list of (shape, color) pairs.\n",
    "    y: torch tensor of shape (9,)\n",
    "    returns: list of tuples (shape, color)\n",
    "    \"\"\"\n",
    "    probs = torch.sigmoid(y) # convert logits to probabilities using sigmoid (will give values between 0 and 1)\n",
    "    idxs = (probs >= 0.5).nonzero(as_tuple=True)[0].tolist() # threshold at 0.5\n",
    "    pairs = []\n",
    "    for i in idxs:\n",
    "        pair = IDX_TO_PAIR[i]\n",
    "        shape, color = pair.split(\"_\")\n",
    "        pairs.append((shape, color))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "# logits = torch.tensor([3.0, -1.0, 0.2, 0.0, 0.0, 2.5, -2.0, 0.0, 0.0])\n",
    "# decoded = decode_vec(logits)\n",
    "# print(decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a74f72",
   "metadata": {},
   "source": [
    "There's a function to make the data usable for training. I represent the labels as the 9-dim tensor mentioned earlier. \n",
    "\n",
    "I also have a function to decode the tensor outputted at inference time. It applies a sigmoid to get probabilities, thresholds, then turns the tensor back into (shape, color) tuples. \n",
    "\n",
    "Next thing to do is load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a75383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label_string(string): # need this since the CSV has labels as strings\n",
    "    \"\"\"\n",
    "    Parse a label string into a list of (shape, color) pairs.\n",
    "    string: str, e.g. \"[(circle_red), (triangle_blue)]\" or \"[]\"\n",
    "    returns: list of tuples (shape, color)\n",
    "    \"\"\"\n",
    "    if string == \"\" or string == \"[]\" or string is None: #handle null or empty arg\n",
    "        return []\n",
    "    s = string.lower().strip()\n",
    "    data = ast.literal_eval(s) # turn the string into a list of tuples\n",
    "    # normalize the tuples\n",
    "    data = [(shape.strip().lower(), color.strip().lower()) for shape, color in data]\n",
    "    return data\n",
    "\n",
    "# Datasets\n",
    "class ShapesColorsDatasetTrain(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for training and validation: (image_tensor, target_vector)\n",
    "    CSV columns: image_path, label\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx, 0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        label_str = self.df.iloc[idx, 1]\n",
    "        pairs = parse_label_string(label_str)\n",
    "        target = encode_pairs(pairs)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kodiak_kaggle_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
